{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6355d1c7-0a9f-4fba-ae3e-78ffe345c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.8.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.20.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.148.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.35.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (5.28.2)\n",
      "Requirement already satisfied: pydantic in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.6.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (4.10.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core->google-generativeai) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->google-generativeai) (2.16.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.66.2)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.66.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55648541-4e91-48e3-a459-37f4d5860235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2f65fa3-f58e-44aa-ba70-8bbcec8f2b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\rohit\\\\Desktop\\\\Rohit\\\\Learnbay\\\\GEN AI by Sundaram'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b10927e-a0a8-408f-9001-81875634b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"AIzaSyBMhmmmKR3k-SVCTMoZ2iY2e-fBc1TRwu4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bf54ae5-7cd3-449a-acfc-0720db888ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-pro-exp-0827\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-exp-0827\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/aqa\n"
     ]
    }
   ],
   "source": [
    "for model in genai.list_models():\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8b9e1ef-992e-4b8a-bb52-66e01b1fc771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Logistic Regression: A Simple Explanation\n",
      "\n",
      "Logistic Regression is a **statistical method used for predicting the probability of a categorical dependent variable.** This means it's designed to answer questions like:\n",
      "\n",
      "* **Is a customer likely to purchase a product?**\n",
      "* **Will a loan application be approved?**\n",
      "* **Is an email likely to be spam?**\n",
      "\n",
      "Unlike linear regression which predicts continuous values, **logistic regression predicts the probability of an event happening (or not)**. This probability is represented by a number between 0 and 1.\n",
      "\n",
      "**How it works:**\n",
      "\n",
      "1. **Data Preparation:** The data is first prepared with independent variables (predictors) and the dependent variable (the outcome we want to predict).\n",
      "2. **Model Building:** A logistic function is used to model the relationship between the independent variables and the probability of the event happening. This function transforms the linear combination of independent variables into a probability.\n",
      "3. **Parameter Estimation:** The parameters of the model are estimated using maximum likelihood estimation. This method aims to find the values of the parameters that best fit the data and maximize the probability of observing the actual outcomes.\n",
      "4. **Prediction:** Once the model is trained, it can be used to predict the probability of the event happening for new data.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Binary Classification:** Typically used for binary outcomes (yes/no, 0/1), but can be extended to multiple categories.\n",
      "* **Probability Prediction:** Output is a probability value, making it useful for understanding the likelihood of an event.\n",
      "* **Interpretability:** The coefficients of the model can be interpreted to understand the influence of independent variables on the outcome.\n",
      "* **Widely Applicable:** Used in various fields like finance, marketing, healthcare, and more.\n",
      "\n",
      "**In a nutshell:**\n",
      "\n",
      "Logistic regression is a powerful tool for predicting the probability of events happening, making it a valuable technique for tasks involving classification and understanding relationships between variables.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Let's say you want to predict if a customer will click on an advertisement based on their age and income. Using logistic regression, you can train a model that takes age and income as inputs and outputs the probability of the customer clicking on the ad. This information can then be used to improve marketing campaigns by targeting customers with a higher probability of clicking.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "prompt = \"What is Logistic Regression ?\"\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43168379-cfe5-43f5-bb40-ee7c59ae9d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatSession(\n",
       "    model=genai.GenerativeModel(\n",
       "        model_name='models/gemini-1.5-flash',\n",
       "        generation_config={},\n",
       "        safety_settings={},\n",
       "        tools=None,\n",
       "        system_instruction=None,\n",
       "        cached_content=None\n",
       "    ),\n",
       "    history=[]\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = model.start_chat(history=[])\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4d3ff5e-6294-4177-b955-ab4231d338e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatSession(\n",
       "    model=genai.GenerativeModel(\n",
       "        model_name='models/gemini-1.5-flash',\n",
       "        generation_config={},\n",
       "        safety_settings={},\n",
       "        tools=None,\n",
       "        system_instruction='You are a helpful AI assistant.\\n                              Your role is to prescribe a medicine and advise related to healtcare.\\n                              Your name is Medibot.\\n                              Incase if someone asked your name please tell them.\\n                              Please dont responded any data other than healtcare question.If user ask anyting else politey responsed them I am healtcare assistant',\n",
       "        cached_content=None\n",
       "    ),\n",
       "    history=[]\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", \n",
    "                              system_instruction=\"\"\"You are a helpful AI assistant.\n",
    "                              Your role is to prescribe a medicine and advise related to healtcare.\n",
    "                              Your name is Medibot.\n",
    "                              Incase if someone asked your name please tell them.\n",
    "                              Please dont responded any data other than healtcare question.If user ask anyting else politey responsed them I am healtcare assistant\"\"\")\n",
    "\n",
    "                              \n",
    "chat = model.start_chat(history=[])\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44acf99a-8332-46cf-9b2b-f4859fe44099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your prompt:  Capital of India\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI response --> I am a healthcare assistant. I can't answer questions about geography. If you have any health-related questions, I'm happy to help. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    prompt = input(\"Enter your prompt: \")\n",
    "    if prompt.lower() in ['exit', 'bye']:\n",
    "        break\n",
    "    response = chat.send_message(prompt)\n",
    "    print(f\" AI response --> {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa6c38-eccc-4093-a867-2f23bab01ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5566416-ad11-45a5-ad05-1e5828f88ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcd2d0e-5196-4bb7-98e4-21a598ccf308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f29d2-6da6-4b34-838b-f391678a781a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
